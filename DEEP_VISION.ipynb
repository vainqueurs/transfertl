{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): pymongo in ./anaconda/lib/python2.7/site-packages\r\n",
      "Cleaning up...\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8312122664125460259\n",
      "]\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 192, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 192, 256, 64)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 192, 256, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 96, 128, 64)   0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 96, 128, 128)  73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 96, 128, 128)  147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 48, 64, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 48, 64, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 48, 64, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 48, 64, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 24, 32, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 24, 32, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 24, 32, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 24, 32, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 12, 16, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 12, 16, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 12, 16, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 12, 16, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 6, 8, 512)     0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'nb_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e4b123134d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m#model.add(conv_base)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m#with tf.device('/gpu:0'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'nb_col'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "keras.__version__\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from keras.backend import tf as K\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import  BatchNormalization\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.applications import VGG16, InceptionV3, ResNet50, VGG19, Xception\n",
    "#conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(768, 1024, 3))# initialize with your own image format\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(768, 1024, 3))# initialize with your own image format\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(192, 256, 3))# initialize with your own image format\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "conv_base.summary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "drop=0.7\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "with tf.device('/gpu:0'):\n",
    "    model = models.Sequential()\n",
    "    for layer in conv_base.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "        model.add(layer)\n",
    "    #model.add(conv_base)\n",
    "#with tf.device('/gpu:0'): \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(ZeroPadding2D((1,1))) \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(ZeroPadding2D((1,1))) \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(ZeroPadding2D((1,1))) \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2))) \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "#for layer in conv_base.layers:\n",
    " #   layer.trainable = False\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[171]:\n",
    "\n",
    "\n",
    "\n",
    "drop=0.7\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "with tf.device('/gpu:0'):\n",
    "    model = models.Sequential()\n",
    "    for layer in conv_base.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "        model.add(layer)\n",
    "    #model.add(conv_base)\n",
    "#with tf.device('/gpu:0'):\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(ZeroPadding2D((1,1))) \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(ZeroPadding2D((1,1))) \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(ZeroPadding2D((1,1))) \n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu')) \n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2))) \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from  skimage import io\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "cd G:\\rsaved\\ISIC-images\\im\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "filename =  'Benign/ISIC_0009872.jpg'\n",
    "y=filename.split('/')[0]\n",
    "X=io.imread('Benign/ISIC_0009872.jpg')\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "\n",
    "# extract features for images and create labels from the names of the folders\n",
    "import os, sys \n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "def resizeimage(IMAGES,factor):\n",
    "    ima=[]\n",
    "    try:\n",
    "        image_rescaled = rescale(IMAGES, factor)\n",
    "        #ima.append(out)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return(image_rescaled)\n",
    "#mod = resizeimage(X_train)\n",
    "\n",
    "def extract(filename =  'Benign/ISIC_0009872.jpg'):\n",
    "    X=0\n",
    "    y=0\n",
    "    try:\n",
    "        print(filename)\n",
    "        X=io.imread(filename) # extract pixel features \n",
    "        X= resizeimage(X,0.25)\n",
    "        y=filename.split('/ISIC')[0]\n",
    "        if y=='Benign': # create label\n",
    "            y=0\n",
    "        else:\n",
    "            y=1\n",
    "        print(y)\n",
    "    except:\n",
    "        print('error' + filename)\n",
    "    return X,y\n",
    "q=extract()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "def createdata(): \n",
    "    X_train = []\n",
    "    y_train=[]\n",
    "    counter = 0\n",
    "    names = ['Benign','Malignant']\n",
    "    for folder in names:\n",
    "        count=0\n",
    "        print(folder)\n",
    "\n",
    "        for fil in os.listdir(folder):\n",
    "            if count <355:\n",
    "\n",
    "                q=None\n",
    "\n",
    "                try:\n",
    "                    q=extract(folder+'/'+fil)\n",
    "                    #print(q[0][2].shape)\n",
    "                    if q[0][2].shape == (256,3):\n",
    "                        X_train.append(q[0])\n",
    "                        y_train.append(q[1])\n",
    "                        count +=1\n",
    "                        counter +=1\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                continue\n",
    "        print(count,fil)\n",
    "    return(X_train,y_train)\n",
    "X, y = createdata()        \n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "from keras.layers import Lambda, Input\n",
    "X_train = []\n",
    "y_train=[]\n",
    "counter = 0 \n",
    "\n",
    "def createdata(maxclass): \n",
    "    names = ['Benign','Malignant']\n",
    "    for folder in names:\n",
    "        count=0\n",
    "        print(folder)\n",
    "        \n",
    "        for fil in os.listdir(folder):\n",
    "            if count <maxclass:\n",
    "                count +=1\n",
    "                q=None\n",
    "                #print(fil)\n",
    "                try:\n",
    "                    q=extract(folder+'/'+fil)\n",
    "                    print(q[0][2].shape)\n",
    "                    if q[0][2].shape == (256,3):\n",
    "                        X_train.append(q[0])\n",
    "                        y_train.append(q[1])\n",
    "                        counter +=1\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                continue\n",
    "    return(X_train,y_train)\n",
    "X, y = createdata(1000)     \n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "len(X),len(y)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# convert the X_train list into an array with one additionnal dimension by stacking elements of the list \n",
    "c= np.stack([X[i] for i in range(len(X))])\n",
    "\n",
    "d= np.array([y]).T\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "d\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(c, d, random_state=1)\n",
    "#X_train=X_train-np.mean(X_train)/np.std(X_train)\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "np.sum(y_train)\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.rmsprop(0.0082), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "\"\"\"from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "datagen.fit(X_train)\n",
    "tense = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=False)\n",
    "tense.set_model(model)\n",
    "model.fit_generator(datagen.flow(X_train[0:500], y_train[0:500], batch_size=6),steps_per_epoch=200, epochs=50, verbose=2, validation_data =(X_train[501:], y_train[501:]),callbacks=[tense])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "#CALLBACKS\n",
    "#This line creates a Callback Tensorboard object, you should capture that object and give it to the fit function of your model.\n",
    "tense = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1, write_graph=True, write_images=False)\n",
    "tense.set_model(model)\n",
    "class_weight = {0 : 1.,1: 3.82}\n",
    "# create checkpoints that we can load later to keep the best model \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#running the model with callbacks\n",
    "model.fit(X_train[0:1100], y_train[0:1100], nb_epoch=100, batch_size=10, verbose=2, validation_split=0.2, shuffle=True, class_weight = class_weight ,callbacks=[tense,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights-improvement-105-0.82.hdf5')\n",
    "\n",
    "\n",
    "# In[74]:\n",
    "\n",
    "\n",
    "model.load_weights('weights-improvement-03-0.84.hdf5')\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "y_pred=model.predict(X_train[1100:])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "scores = model.evaluate(X_train[1100:], y_train[1100:], verbose=2)\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "yp=y_pred\n",
    "for i in range(1100,1351):\n",
    "    if np.abs(y_pred[i-1100]-1)>0.5:\n",
    "        yp[i-1100]= 0 \n",
    "    else:\n",
    "        yp[i-1100]=1\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train[1100:1351], yp)\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "(168+59)/251\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "(166+28)/251\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "28/(28+15)\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "np.sum(y_train[1100:1351])\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "251-70\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
